# -*- coding: utf-8 -*-
"""Project_01_512

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1i5m7XQu4OgzCKD1XlSREIAhJm7FAqUwh
"""

from google.colab import files

# Upload the ZIP file
print("Please upload your ZIP file.")
uploaded = files.upload()

# Save the file name for further use
zip_file_name = list(uploaded.keys())[0]
print(f"Uploaded file: {zip_file_name}")

import os
print(os.listdir('/content'))  # Lists all files in the /content directory

import zipfile
import os

# Path to the uploaded ZIP file
zip_file_name = "/content/Project1Files-GA - ForStudents.zip"

# Path to the extraction folder
extraction_folder = "/content/extracted_files"

# Extract the ZIP file
with zipfile.ZipFile(zip_file_name, 'r') as zip_ref:
    zip_ref.extractall(extraction_folder)

print(f"Files extracted to: {extraction_folder}")

for root, dirs, files in os.walk(extraction_folder):
    for file in files:
        print(os.path.join(root, file))  # Full path of each file

import os

extraction_folder = "/content/extracted_files"

# List all files in the extracted folder
for root, dirs, files in os.walk(extraction_folder):
    for file in files:
        print(os.path.join(root, file))

import pandas as pd

# Path to the CSV file
csv_file = "/content/extracted_files/Project1Files-GA - ForStudents/Train-pIC50.csv"

# Read the CSV file using pandas
data = pd.read_csv(csv_file)

# Display the first few rows of the data
print(data.head())

# Path to the Python file
python_file = "/content/extracted_files/Project1Files-GA - ForStudents/mlr.py"

# Read and display the content of the Python file
with open(python_file, 'r') as f:
    content = f.read()
    print(content)

import os

# Directory containing extracted files
extracted_folder = "/content/extracted_files/Project1Files-GA - ForStudents"

# List all files and directories
for root, dirs, files in os.walk(extracted_folder):
    print(f"Directory: {root}")
    for file in files:
        print(f"  File: {file}")

!pip install pandas numpy scikit-learn

import pandas as pd

# Define file paths
train_file = '/content/extracted_files/Project1Files-GA - ForStudents/Train-Data.csv'
test_file = '/content/extracted_files/Project1Files-GA - ForStudents/Test-Data.csv'
validation_file = '/content/extracted_files/Project1Files-GA - ForStudents/Validation-Data.csv'

# Load data
train_data = pd.read_csv(train_file)
test_data = pd.read_csv(test_file)
validation_data = pd.read_csv(validation_file)

# Check the data to understand its structure
print("Train Data:")
print(train_data.head())
print("Validation Data:")
print(validation_data.head())
print("Test Data:")
print(test_data.head())

import numpy as np
import pandas as pd
import random

# Parameters
population_size = 50
num_features = 385
selection_probability = 0.015
min_features = 5  # Minimum number of selected features per model

# Initialize population with a minimum of 5 selected features
def initialize_population(population_size, num_features, min_features=5, selection_probability=0.015):
    population = []
    for _ in range(population_size):
        while True:
            # Randomly select features with the given probability
            model = np.random.choice([0, 1], size=num_features, p=[1 - selection_probability, selection_probability])
            # Check if the model has at least the minimum number of features
            if model.sum() >= min_features:
                population.append(model)
                break
    return pd.DataFrame(population, columns=[f'feature_{i}' for i in range(num_features)])

# Initialize population DataFrame
population_df = initialize_population(population_size, num_features)

from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score

# Dummy dataset (replace with your actual data)
X_train, y_train = np.random.rand(100, num_features), np.random.rand(100)  # Replace with actual training data
X_val, y_val = np.random.rand(50, num_features), np.random.rand(50)        # Replace with actual validation data
X_test, y_test = np.random.rand(50, num_features), np.random.rand(50)      # Replace with actual test data

def calculate_metrics(selected_features):
    model = LinearRegression()

    # Select features based on the model (boolean indexing)
    X_train_sel = X_train[:, selected_features]
    X_val_sel = X_val[:, selected_features]
    X_test_sel = X_test[:, selected_features]

    # Fit model on training data
    model.fit(X_train_sel, y_train)

    # Predict and calculate R², Q² for each dataset
    r2_train = r2_score(y_train, model.predict(X_train_sel))
    r2_val = r2_score(y_val, model.predict(X_val_sel))
    r2_test = r2_score(y_test, model.predict(X_test_sel))

    # Assuming Q² is calculated similarly to R² for demonstration
    q2 = r2_val  # Adjust if Q² calculation differs

    return r2_train, q2, r2_val, r2_test

fitness_data = []

for i in range(population_size):
    # Boolean array indicating selected features for this model
    selected_features = population_df.iloc[i].astype(bool).values
    r2_train, q2, r2_val, r2_test = calculate_metrics(selected_features)

    # Calculate fitness score (lower fitness is better)
    fitness = 1 - r2_train  # Customize based on requirements

    # Store model metrics
    fitness_data.append([selected_features.nonzero()[0], fitness, "MLR", r2_train, q2, r2_val, r2_test])

# Create DataFrame from fitness data
fitness_df = pd.DataFrame(fitness_data, columns=["Descriptor ID", "Fitness", "Model", "R2", "Q2", "R2Pred_Validation", "R2Pred_Test"])

# Helper function to convert a list of selected feature indices to a binary array
def indices_to_binary_array(indices, length):
    binary_array = np.zeros(length, dtype=int)
    binary_array[indices] = 1
    return binary_array

# Crossover and mutation function with minimum feature count enforcement
def crossover_and_mutate(parent1, parent2, mutation_rate=0.01, min_features=5):
    # Perform single-point crossover
    crossover_point = random.randint(1, num_features - 1)
    child = np.concatenate([parent1[:crossover_point], parent2[crossover_point:]])

    # Apply mutation
    for i in range(num_features):
        if random.random() < mutation_rate:
            child[i] = 1 - child[i]  # Flip the bit

    # Ensure the child has at least `min_features` selected features
    while child.sum() < min_features:
        index = random.randint(0, num_features - 1)
        child[index] = 1

    return child

# Generate the next population
new_population = []
sorted_population = fitness_df.sort_values(by="Fitness").head(2)  # Select top 2 models

for _ in range(population_size):
    # Convert Descriptor ID lists to binary arrays
    parent1 = indices_to_binary_array(sorted_population.iloc[0]["Descriptor ID"], num_features)
    parent2 = indices_to_binary_array(sorted_population.iloc[1]["Descriptor ID"], num_features)

    # Generate child with crossover and mutation
    child = crossover_and_mutate(parent1, parent2, mutation_rate=0.01, min_features=5)
    new_population.append(child)

# Convert new population to DataFrame
new_population_df = pd.DataFrame(new_population, columns=[f'feature_{i}' for i in range(num_features)])

import csv
from datetime import datetime
import pytz

# Get current time in Pacific Time Zone
pacific_tz = pytz.timezone("America/Los_Angeles")
current_time = datetime.now(pacific_tz)

# Format day name and time in 12-hour Pacific format
day_name = current_time.strftime("%A")  # Full weekday name (e.g., Monday)
time_str = current_time.strftime("%I_%M_%p")  # 12-hour format with AM/PM (e.g., 03_45_PM)
filename = f"{day_name}_{time_str}.csv"  # e.g., "Monday_03_45_PM.csv"

# Save fitness results to CSV with dynamic filename
with open(filename, mode="w", newline="") as file:
    writer = csv.writer(file)
    writer.writerow(["Descriptor ID", "Fitness", "Model", "R2", "Q2", "R2Pred_Validation", "R2Pred_Test"])
    for index, row in fitness_df.iterrows():
        writer.writerow(row)

print(f"Results have been saved to {filename}")